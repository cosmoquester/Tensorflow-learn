{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "\n",
    "num_of_episodes = 2000\n",
    "learning_rate = 0.01\n",
    "discount = .99\n",
    "rList=[]\n",
    "state_buffer = deque(maxlen=10000)\n",
    "\n",
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    \n",
    "    def __init__(self, sess, size_in, size_out, name=\"main\"):\n",
    "        self.sess = sess\n",
    "        self.size_in = size_in\n",
    "        self.size_out = size_out\n",
    "        self.name = name\n",
    "        \n",
    "        self.build_network()\n",
    "    \n",
    "    def build_network(self, h_size=32, learning_rate=0.01):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.X = tf.placeholder(tf.float32, [None, self.size_in])\n",
    "            self.Y = tf.placeholder(tf.float32)\n",
    "            self.A = tf.placeholder(tf.float32)\n",
    "\n",
    "            layer1 = tf.layers.dense(self.X, h_size, activation=tf.nn.relu, )\n",
    "            self.Qpred = tf.layers.dense(layer1, self.size_out)\n",
    "\n",
    "            self.cost = tf.reduce_sum(tf.square(self.Y*self.A - self.Qpred*self.A))\n",
    "            self.train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "            \n",
    "    def predict(self, state):\n",
    "        return self.sess.run(self.Qpred, {self.X: np.reshape(state, [-1, self.size_in])})\n",
    "                             \n",
    "    def update(self, state_array, reward_array, action_array):\n",
    "        return self.sess.run([self.cost,self.train], feed_dict={self.X:state_array, self.Y:reward_array, self.A:action_array})\n",
    "    \n",
    "def get_copy_var_ops(dest_scope_name, src_scope_name):\n",
    "\n",
    "    op_holder = []\n",
    "\n",
    "    src_vars = tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "\n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "\n",
    "    return op_holder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    return np.identity(16)[x:x+1]\n",
    "\n",
    "def show_play(env, sess, DQN):\n",
    "    state = env.reset()\n",
    "    env.render()\n",
    "    reward_all = 0\n",
    "    while True:\n",
    "        action = np.argmax(DQN.predict(one_hot(state)))\n",
    "        state, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        print(\"State: \", state, \"Action: \", action,\"Reward: \", reward, \"Info: \", info)\n",
    "        reward_all += reward\n",
    "        if done:\n",
    "            break\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.596\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 4, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 4, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "('State: ', 8, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 4, 'Action: ', 3, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 0, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 4, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 4, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "('State: ', 8, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "('State: ', 8, 'Action: ', 3, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "('State: ', 9, 'Action: ', 3, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "('State: ', 10, 'Action: ', 1, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 6, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n",
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "('State: ', 5, 'Action: ', 0, 'Reward: ', 0.0, 'Info: ', {'prob': 0.3333333333333333})\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    mainDQN = DQN(sess, env.observation_space.n, env.action_space.n)\n",
    "    targetDQN = DQN(sess, env.observation_space.n, env.action_space.n, \"target\")\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    copy_ops = get_copy_var_ops(dest_scope_name=\"target\", src_scope_name=\"main\")\n",
    "    # copy from main to target\n",
    "    sess.run(copy_ops)\n",
    "    \n",
    "    for step in range(num_of_episodes):\n",
    "\n",
    "        s = env.reset()\n",
    "        e = 1. / ((step / 10) + 1)\n",
    "        rAll = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            Qs = mainDQN.predict(one_hot(s))\n",
    "            \n",
    "            if np.random.rand(1) < e:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = np.argmax(Qs)     \n",
    "            \n",
    "            s1, reward, done, info = env.step(a)\n",
    "            \n",
    "            if done:\n",
    "                Qs[0,a] = reward\n",
    "            else:\n",
    "                Qs1 = targetDQN.predict(one_hot(s1))\n",
    "                Qs[0,a] = reward + discount * np.max(Qs1)\n",
    "                            \n",
    "            state_buffer.append([s,Qs[0],a])\n",
    "            \n",
    "            if len(state_buffer) > 100:\n",
    "                mini_batch = random.sample(state_buffer, 100)\n",
    "                state_array = np.array([one_hot(x[0])[0] for x in mini_batch])\n",
    "                reward_array = np.array([x[1] for x in mini_batch])\n",
    "                action_array = np.array([np.identity(4)[x[2]] for x in mini_batch])\n",
    "                \n",
    "                mainDQN.update(state_array, reward_array, action_array)\n",
    "            \n",
    "            rAll += reward\n",
    "            s = s1\n",
    "        rList.append(rAll)\n",
    "        \n",
    "        if step % 5 == 0:\n",
    "            sess.run(copy_ops)\n",
    "            \n",
    "    rList = rList[1500:]\n",
    "    print(\"Success rate: \" + str(sum(rList) / len(rList)))\n",
    "    plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "    plt.show()\n",
    "    \n",
    "    show_play(env, sess, mainDQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
